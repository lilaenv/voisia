import Anthropic from '@anthropic-ai/sdk';
import { AnthropicModelParams, ChatMessage, TokenUsage } from '../interfaces';

const anthropic = new Anthropic();

/**
 * Generate the next message in the conversation and return token usage.
 * @param prompt - Array of conversation (history) messages.
 * @param modelParams - Parameters that control the model's behavior.
 * @returns Content generated by the specified model and token usage.
 */
export async function generateAnthropicResponse(
  prompt: ChatMessage[],
  modelParams: AnthropicModelParams,
): Promise<{ messages: ChatMessage[]; tokenUsage: TokenUsage | null }> {
  const response = await anthropic.messages.create({
    model: modelParams.model,
    messages: prompt.map((p) => ({
      role: p.role as Anthropic.MessageParam['role'],
      content: p.content,
    })),
    system: modelParams.system,
    max_tokens: modelParams.maxOutputTokens,
    temperature: modelParams.temperature,
    top_p: modelParams.topP,
  });

  // Convert to ChatMessage format: [{'role': 'assistant', 'content': "Hi, I'm Claude."}]
  const convertedResponse = response.content
    .filter((block) => block.type === 'text')
    .map((block) => (block as Anthropic.TextBlock).text)
    .join('');

  // Get token usage from the response
  const tokenUsage = getAnthropicTokenUsage(response);

  return {
    messages: [{ role: 'assistant', content: convertedResponse }],
    tokenUsage,
  };
}

/**
 * Get the token usage for an Anthropic response.
 * @param response - The Anthropic response object.
 * @returns The token usage or null if the response is invalid.
 */
export function getAnthropicTokenUsage(response: Anthropic.Message): TokenUsage | null {
  try {
    if (response && response.usage) {
      return {
        inputTokens: response.usage.input_tokens || 0,
        outputTokens: response.usage.output_tokens || 0,
      };
    }
    return null;
  } catch (err) {
    console.error('Failed to get token usage:', err);
    return null;
  }
}
